# generated by datamodel-codegen:
#   filename:  catalog.yml
#   timestamp: 2024-04-09T15:06:29+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class ReadSyncMode(Enum):
    FULL_REFRESH = 'FULL_REFRESH'
    INCREMENTAL = 'INCREMENTAL'


class WriteSyncMode(Enum):
    APPEND = 'APPEND'
    UPSERT = 'UPSERT'
    REPLACE = 'REPLACE'


class DatDocumentStream(BaseModel):
    class Config:
        extra = 'allow'

    name: str = Field(..., description='The name of the document stream.')
    namespace: Optional[str] = Field(
        None, description='The namespace the data is associated with.'
    )
    json_schema: Optional[Dict[str, Any]] = Field(
        None, description='The JSON schema for the document stream.'
    )
    read_sync_mode: Optional[ReadSyncMode] = Field(
        'INCREMENTAL',
        description='A list of supported sync modes for the stream while reading.',
    )
    write_sync_mode: Optional[WriteSyncMode] = Field(
        'APPEND',
        description='A list of supported sync modes for the stream while writing.',
    )
    cursor_field: Optional[str] = Field(
        None,
        description='The path to the field used to determine if a record is new or modified.\nREQUIRED for INCREMENTAL sync mode.',
    )


class Crawler(DatDocumentStream):
    name: Optional[str] = 'crawler'
    namespace: Optional[str] = Field(
        None, description='namespace the data is associated with'
    )
    site_url: str = Field(..., description='URL of the webpage you want to crawl')


class WebCrawlerCatalog(BaseModel):
    document_streams: List[Crawler]
